# -*- coding: utf-8 -*-
"""ass3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g1SIg95jtAKfZzR_SQUzx_bq1XBCvKne
"""

import os
import shutil
from PIL import Image

base_dir = "/content/drive/MyDrive/cars_dataset"
image_dir = os.path.join(base_dir, "Images")
annotation_dir = os.path.join(base_dir, "Annotations")
label_dir = os.path.join(base_dir, "labels_yolo")
split_dir = os.path.join(base_dir, "ImageSets")

print("Klasör yolları:")
print(f"Images: {image_dir}")
print(f"Annotations: {annotation_dir}")
print(f"Labels (YOLO): {label_dir}")
print(f"ImageSets: {split_dir}")

print("\n train / val / test klasörleri oluşturuluyor...")
for split in ["train", "val", "test"]:
    os.makedirs(os.path.join(image_dir, split), exist_ok=True)
    os.makedirs(os.path.join(label_dir, split), exist_ok=True)
print("Klasörler hazır.")

def find_image_path(image_base_name):
    possible_exts = ['.jpg', '.JPG', '.jpeg', '.png', '.PNG']
    for ext in possible_exts:
        full_path = os.path.join(image_dir, image_base_name + ext)
        if os.path.exists(full_path):
            return full_path
    return None

for split in ["train", "val", "test"]:
    print(f"\n [{split.upper()}] başlatılıyor...")

    split_file = os.path.join(split_dir, f"{split}.txt")
    with open(split_file, "r") as f:
        image_ids = [line.strip() for line in f if line.strip()]

    print(f" {len(image_ids)} adet görüntü listelendi ({split_file})")

    for idx, image_id in enumerate(image_ids):
        print(f"\n [{split}] {idx+1}/{len(image_ids)} → {image_id}")

        img_src = find_image_path(image_id)
        img_dst = os.path.join(image_dir, split, f"{image_id}.jpg")
        ann_src = os.path.join(annotation_dir, f"{image_id}.txt")
        label_dst = os.path.join(label_dir, split, f"{image_id}.txt")

        if img_src:
            print(f" Görsel bulundu: {img_src}")
            shutil.copyfile(img_src, img_dst)
            print(f" Kopyalandı → {img_dst}")
        else:
            print(f" Görsel bulunamadı: {image_id}")
            continue

        if os.path.exists(ann_src):
            print(f" Etiket bulundu: {ann_src}")
            img = Image.open(img_src)
            img_width, img_height = img.size

            yolo_lines = []
            with open(ann_src, "r") as ann_file:
                for line in ann_file:
                    parts = line.strip().split()
                    if len(parts) != 5:
                        print(" Hatalı etiket satırı atlandı.")
                        continue
                    x1, y1, x2, y2, _ = map(int, parts)
                    x_center = (x1 + x2) / 2.0 / img_width
                    y_center = (y1 + y2) / 2.0 / img_height
                    width = (x2 - x1) / img_width
                    height = (y2 - y1) / img_height
                    yolo_lines.append(f"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")

            with open(label_dst, "w") as out_file:
                out_file.write("\n".join(yolo_lines))
            print(f" Etiket dönüştürüldü → {label_dst}")
        else:
            print(f"Etiket dosyası bulunamadı: {ann_src}")

import os
import shutil
from PIL import Image

base_dir = "/content/drive/MyDrive/cars_dataset"


yaml_content = f"""
path: {base_dir}
train: images/train
val: images/val
test: images/test

names:
  0: car
"""

with open(os.path.join(base_dir, "dataset.yaml"), "w") as f:
    f.write(yaml_content.strip())

print(" dataset.yaml başarıyla oluşturuldu.")
!rm /content/drive/MyDrive/cars_dataset/Images/*.cache

import os

images_dir = "/content/drive/MyDrive/cars_dataset/images/val"
labels_dir = "/content/drive/MyDrive/cars_dataset/labels/val"

matched = 0
unmatched = []

for fname in os.listdir(images_dir):
    basename, _ = os.path.splitext(fname)
    label_path = os.path.join(labels_dir, basename + ".txt")
    if os.path.exists(label_path):
        matched += 1
    else:
        unmatched.append(basename)

print(f" {matched} görüntü eşleşti.")
if unmatched:
    print(f" {len(unmatched)} eşleşmeyen dosya var. İlk 5 tanesi:")
    print(unmatched[:5])
else:
    print(" Tüm görseller etiketlerle eşleşiyor.")

"""-- The ultralytics package is a powerful and user-friendly Python library developed by the creators of YOLO (You Only Look Once), designed for object detection, segmentation, and tracking tasks. It provides a high-level API through the YOLO() class, allowing users to easily train, validate, and run inference with state-of-the-art YOLOv5 and YOLOv8 models. The package also supports command-line usage and includes utilities for dataset preparation, augmentation, visualization, and exporting models to various formats. Installing it with --upgrade ensures that the latest version is used, which includes the most recent features, performance improvements, and bug fixes. This makes it an essential tool for modern deep learning workflows in computer vision."""

!pip install ultralytics --upgrade

"""#**Model 1: YOLOv8n – Default Optimizer and Learning Rate**

Parameters:

Model: yolov8n.pt

Optimizer: default (AdamW via optimizer='auto')

Learning rate: default (0.01)

Epochs: 50

Batch size: 16

Image size: 640x640

Freeze: None (all layers are trainable)



This baseline model was trained using YOLOv8n with default settings provided by the Ultralytics library. After training for 50 epochs on the car counting dataset, the model achieved a Mean Squared Error (MSE) of 2.7350 and an Exact Match Accuracy (EMA) of 46.50% on the test set of 200 images. These results indicate that the default configuration is quite effective for the object counting task, achieving a balance between prediction accuracy and generalization without any manual tuning. It serves as a reliable reference point for comparing the impact of architectural modifications, freezing strategies, and hyperparameter changes in later experiments.
"""

from ultralytics import YOLO
from google.colab import drive
drive.mount('/content/drive', force_remount=True)
!rm /content/drive/MyDrive/cars_dataset/images/*.cache

# YOLOv8n  modeli
model = YOLO('yolov8n.pt')


############ default optimizer and leaarning rate
model.train(
    data="/content/drive/MyDrive/cars_dataset/dataset.yaml",
    epochs=50,
    imgsz=640,
    batch=16,
    name="yolo_car_counting_v8n",
    device=0
)

from ultralytics import YOLO
model5 = YOLO("yolov8n.pt")
model5.info()

from IPython.display import Image, display
display(Image(filename="/content/runs/detect/yolo_car_counting_v8n/results.png"))

from ultralytics import YOLO
import os
import numpy as np


model = YOLO("/content/runs/detect/yolo_car_counting_v8n/weights/best.pt")


img_dir = "/content/drive/MyDrive/cars_dataset/images/test"
label_dir = "/content/drive/MyDrive/cars_dataset/labels/test"

image_names = sorted(os.listdir(img_dir))
exact_matches = 0
sq_errors = []
total = 0

for name in image_names:
    base, _ = os.path.splitext(name)
    img_path = os.path.join(img_dir, name)
    label_path = os.path.join(label_dir, base + ".txt")

    if not os.path.exists(label_path):
        continue

    with open(label_path, "r") as f:
        gt_count = len(f.readlines())

    result = model(img_path, conf=0.25, iou=0.5, verbose=False)
    pred_count = len(result[0].boxes)

    if pred_count == gt_count:
        exact_matches += 1

    sq_errors.append((pred_count - gt_count) ** 2)
    total += 1

mse = np.mean(sq_errors)
ema = (exact_matches / total) * 100

print(f" Mean Squared Error (MSE): {mse:.4f}")
print(f" Exact Match Accuracy (EMA): {ema:.2f}%")
print(f" Değerlendirilen görüntü sayısı: {total}")

import matplotlib.pyplot as plt

ema =46.50  # Exact Match Accuracy
mse = 2.7350  # Mean Squared Error

fig, ax1 = plt.subplots(figsize=(7, 5))


ax1.bar(['Exact Match Accuracy'], [ema], color='skyblue', label='EMA (%)')
ax1.set_ylim(0, 100)
ax1.set_ylabel('EMA (%)', color='skyblue')
ax1.set_title('Exact Match Accuracy ve Mean Squared Error')


ax2 = ax1.twinx()
ax2.plot(['MSE'], [mse], marker='o', markersize=10, color='tomato', label='MSE')
ax2.set_ylabel('MSE', color='tomato')
ax2.set_ylim(0, max(mse * 2, 1))

ax1.text(-0.05, ema + 2, f"{ema:.2f}%", color='blue', fontsize=10)
ax2.text(0.95, mse + 0.05, f"{mse:.3f}", color='tomato', fontsize=10)

fig.legend(loc="upper right", bbox_to_anchor=(0.85, 0.9))
plt.grid(axis='y', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

import os

test_dir = "/content/drive/MyDrive/cars_dataset/images/test"
sample_images = sorted(os.listdir(test_dir))[:3]

print("Seçilen örnek görseller:")
for img in sample_images:
    print(img)

from ultralytics import YOLO

model = YOLO("/content/runs/detect/yolo_car_counting_v8n/weights/best.pt")

for img_name in sample_images:
    img_path = os.path.join(test_dir, img_name)
    model.predict(img_path, save=True, conf=0.25, iou=0.5, verbose=False)

from IPython.display import Image, display

predict_dir = "/content/runs/detect/predict3"

for img_name in sample_images:
    display(Image(filename=os.path.join(predict_dir, img_name), width=800))
    print("\n")

label_dir = "/content/drive/MyDrive/cars_dataset/labels/test"

for img_name in sample_images:
    base, _ = os.path.splitext(img_name)
    label_path = os.path.join(label_dir, base + ".txt")
    if os.path.exists(label_path):
        with open(label_path, "r") as f:
            true_count = len(f.readlines())
    else:
        true_count = 0

    pred_result = model(os.path.join(test_dir, img_name), conf=0.25, verbose=False)
    pred_count = len(pred_result[0].boxes)

    print(f"{img_name} → GT: {true_count}, Prediction: {pred_count}")

"""#**Model 2: YOLOv8n – Freeze First 5 Layers (Default Optimizer and Learning Rate)**

Parameters:

Model: yolov8n.pt

Freeze: 5 (stem + first 2 backbone blocks)

Optimizer: default (AdamW)

Learning rate: default (0.01)

Epochs: 50

Batch size: 16

Image size: 640x640


In this experiment, the first five layers of the YOLOv8n model were frozen during training, including the initial convolutional stem and the first two C2f backbone blocks. This approach preserves the low-level feature extractors learned from pretraining while allowing the deeper layers and detection head to adapt to the new car counting dataset. After training for 50 epochs, the model achieved a Mean Squared Error (MSE) of 2.2700 and an Exact Match Accuracy (EMA) of 44.50% on a test set of 200 images. These results are only slightly lower than the baseline model where all layers were trainable, suggesting that early convolutional features are general enough to transfer well without retraining. Freezing these layers also reduces the number of trainable parameters, leading to faster training and potentially lower memory usage. This configuration demonstrates a good trade-off between efficiency and accuracy, making it a practical option for scenarios with limited computational resources or when faster convergence is desired.
"""

from ultralytics import YOLO

model = YOLO("yolov8n.pt")

###freeze 5 later deafult optimizer and leanirng rate(0.01)
model.train(
    data="/content/drive/MyDrive/cars_dataset/dataset.yaml",
    epochs=50,
    imgsz=640,
    batch=16,
    name="yolo_freeze5",
    device=0,
    freeze=5
)

from IPython.display import Image, display
display(Image(filename="/content/runs/detect/yolo_freeze5/results.png"))

from ultralytics import YOLO
import os
import numpy as np

def evaluate_model(model_path, img_dir, label_dir, conf=0.25, iou=0.5):


    model = YOLO(model_path)

    image_names = sorted(os.listdir(img_dir))
    exact_matches = 0
    sq_errors = []
    total = 0

    for name in image_names:
        base, _ = os.path.splitext(name)
        img_path = os.path.join(img_dir, name)
        label_path = os.path.join(label_dir, base + ".txt")

        if not os.path.exists(label_path):
            continue

        with open(label_path, "r") as f:
            gt_count = len(f.readlines())

        result = model(img_path, conf=conf, iou=iou, verbose=False)
        pred_count = len(result[0].boxes)

        if pred_count == gt_count:
            exact_matches += 1

        sq_errors.append((pred_count - gt_count) ** 2)
        total += 1

    mse = np.mean(sq_errors)
    ema = (exact_matches / total) * 100

    print(f" Model: {model_path}")
    print(f" Mean Squared Error (MSE): {mse:.4f}")
    print(f" Exact Match Accuracy (EMA): {ema:.2f}%")
    print(f"  Değerlendirilen görüntü sayısı: {total}")

    return ema, mse, total

evaluate_model(
    model_path="/content/runs/detect/yolo_freeze5/weights/best.pt",
    img_dir="/content/drive/MyDrive/cars_dataset/images/test",
    label_dir="/content/drive/MyDrive/cars_dataset/labels/test"
)

import matplotlib.pyplot as plt

def plot_ema_mse(ema, mse, title="Exact Match Accuracy ve Mean Squared Error"):

    fig, ax1 = plt.subplots(figsize=(7, 5))

    ax1.bar(['Exact Match Accuracy'], [ema], color='skyblue', label='EMA (%)')
    ax1.set_ylim(0, 100)
    ax1.set_ylabel('EMA (%)', color='skyblue')
    ax1.set_title(title)

    ax2 = ax1.twinx()
    ax2.plot(['MSE'], [mse], marker='o', markersize=10, color='tomato', label='MSE')
    ax2.set_ylabel('MSE', color='tomato')
    ax2.set_ylim(0, max(mse * 2, 1))

    ax1.text(-0.05, ema + 2, f"{ema:.2f}%", color='blue', fontsize=10)
    ax2.text(0.95, mse + 0.05, f"{mse:.3f}", color='tomato', fontsize=10)

    fig.legend(loc="upper right", bbox_to_anchor=(0.85, 0.9))
    plt.grid(axis='y', linestyle='--', alpha=0.6)
    plt.tight_layout()
    plt.show()

plot_ema_mse(44.50,2.2700)

from ultralytics import YOLO
from IPython.display import Image, display
import os

def predict_show_compare(model_path, image_dir, label_dir, predict_dir,
                          conf=0.25, iou=0.5, num_images=3):

    sample_images = sorted(os.listdir(image_dir))[:num_images]
    print(f"Prediction output directory: {predict_dir}\n")

    print(" Selected Images:")
    for img in sample_images:
        print("•", img)

    model = YOLO(model_path)

    print("\n Prediction and Count Comparison:\n")
    for img_name in sample_images:
        img_path = os.path.join(image_dir, img_name)
        base, _ = os.path.splitext(img_name)
        label_path = os.path.join(label_dir, base + ".txt")

        true_count = 0
        if os.path.exists(label_path):
            with open(label_path, "r") as f:
                true_count = len(f.readlines())

        result = model(img_path, conf=conf, iou=iou, save=True, save_dir=predict_dir, verbose=False)
        pred_count = len(result[0].boxes)

        display(Image(filename=os.path.join(predict_dir, img_name), width=800))
        print(f" {img_name} → GT: {true_count} car(s), Prediction: {pred_count} car(s)\n")

predict_show_compare(
    model_path="/content/runs/detect/yolo_freeze5/weights/best.pt",
    image_dir="/content/drive/MyDrive/cars_dataset/images/test",
    label_dir="/content/drive/MyDrive/cars_dataset/labels/test",
    predict_dir="runs/detect/predict4",
    num_images=3
)

"""#**Model 3 : YOLOv8n – Freeze First 5 Layers with Adam Optimizer and Lower Learning Rate (0.001)**

Parameters:

Model: yolov8n.pt

Freeze: 5 (stem + first 2 backbone blocks)

Optimizer: Adam

Learning rate: 0.001

Epochs: 50

Batch size: 16

Image size: 640x640


In this configuration, the same 5-layer freezing strategy as the previous experiment was used, but with a manually specified optimizer (Adam) and a reduced learning rate of 0.001. The goal was to examine how a lower learning rate would affect convergence and generalization when fewer parameters are being updated. After 50 epochs of training, the model achieved a Mean Squared Error (MSE) of 3.4800 and an Exact Match Accuracy (EMA) of 42.50% on the 200-image test set. Compared to the baseline and previous freeze=5 model with a default learning rate, performance decreased slightly in both metrics. This suggests that a learning rate of 0.001 may be too conservative in this context, especially when combined with the Adam optimizer, which already performs internal adaptive scaling. The lower learning rate may have slowed convergence, preventing the model from fully adapting to the dataset within the given epoch limit. These results highlight the importance of tuning learning rate in conjunction with freezing strategies and optimizer choice to balance training stability and model adaptability.
"""

from ultralytics import YOLO

model = YOLO("yolov8n.pt")


######### freeze 5 layers aptimizer adam and learning rate 0.001
model.train(
    data="/content/drive/MyDrive/cars_dataset/dataset.yaml",
    epochs=50,
    imgsz=640,
    batch=16,
    name="yolo_freeze5_lr001",
    device=0,
    freeze=5,
    lr0=0.001,
    optimizer="Adam"

)

from IPython.display import Image, display
display(Image(filename="/content/runs/detect/yolo_freeze5_lr001/results.png"))

evaluate_model(
    model_path="/content/runs/detect/yolo_freeze5_lr001/weights/best.pt",
    img_dir="/content/drive/MyDrive/cars_dataset/images/test",
    label_dir="/content/drive/MyDrive/cars_dataset/labels/test"
)

plot_ema_mse(42.50,3.4800)


predict_show_compare(
    model_path="/content/runs/detect/yolo_freeze5_lr001/weights/best.pt",
    image_dir="/content/drive/MyDrive/cars_dataset/images/test",
    label_dir="/content/drive/MyDrive/cars_dataset/labels/test",
    predict_dir="runs/detect/predict10",
    num_images=3
)

"""#**Model 4: YOLOv8n – Freeze First 5 Layers with Adam Optimizer and Learning Rate 0.005**

Parameters:

Model: yolov8n.pt

Freeze: 5 (stem + first 2 backbone blocks)

Optimizer: Adam

Learning rate: 0.005

Epochs: 50

Batch size: 16

Image size: 640x640


This training configuration again froze the first five layers of the YOLOv8n model but used the Adam optimizer with a slightly higher learning rate of 0.005. The aim was to observe whether increasing the learning rate could accelerate convergence and improve learning dynamics for the trainable layers. After 50 epochs of training, the model achieved a Mean Squared Error (MSE) of 3.2700 and an Exact Match Accuracy (EMA) of 42.00% on the 200-image test set. These results are very close to the previous Adam experiment with a learning rate of 0.001, indicating that neither value significantly improved performance over the default optimizer. The model underperformed compared to the baseline (lr0=0.01, optimizer=auto) despite the higher learning rate, possibly due to overfitting or instability in gradient updates caused by the combination of a moderate learning rate and frozen layers. This suggests that manually adjusting learning rate and optimizer requires careful balancing, and that the default configuration provided by Ultralytics (which uses adaptive tuning internally) may be more robust for this task unless further fine-tuning is applied.
"""

from ultralytics import YOLO

model = YOLO("yolov8n.pt")

######### freeze 5 layers aptimizer adam and learning rate 0.005

model.train(
    data="/content/drive/MyDrive/cars_dataset/dataset.yaml",
    epochs=50,
    imgsz=640,
    batch=16,
    name="yolo_freeze5_lr005",
    device=0,
    freeze=5,
    lr0=0.005,
    optimizer="Adam"

)

from IPython.display import Image, display
display(Image(filename="/content/runs/detect/yolo_freeze5_lr005/results.png"))

evaluate_model(
    model_path="/content/runs/detect/yolo_freeze5_lr005/weights/best.pt",
    img_dir="/content/drive/MyDrive/cars_dataset/images/test",
    label_dir="/content/drive/MyDrive/cars_dataset/labels/test"
)

plot_ema_mse(42.50,3.4800)


predict_show_compare(
    model_path="/content/runs/detect/yolo_freeze5_lr005/weights/best.pt",
    image_dir="/content/drive/MyDrive/cars_dataset/images/test",
    label_dir="/content/drive/MyDrive/cars_dataset/labels/test",
    predict_dir="runs/detect/predict11",
    num_images=3
)

"""#**Model 5: YOLOv8n – Freeze First 5 Layers with SGD Optimizer and Learning Rate 0.005**

Parameters:

Model: yolov8n.pt

Freeze: 5 (stem + first 2 backbone blocks)

Optimizer: SGD

Learning rate: 0.005

Epochs: 50

Batch size: 16

Image size: 640x640


In this configuration, the model was trained with the first five layers frozen and the Stochastic Gradient Descent (SGD) optimizer, using a moderate learning rate of 0.005. This experiment was designed to compare the effects of using a non-adaptive optimizer (SGD) versus adaptive optimizers like Adam. After 50 epochs, the model yielded a Mean Squared Error (MSE) of 3.6300 and an Exact Match Accuracy (EMA) of 43.00% on the 200-image test set. While the EMA is slightly higher than the model trained with Adam (lr=0.005), the MSE increased, indicating less consistent bounding box predictions overall. This result suggests that while SGD may improve stability in classification confidence (hence slightly better EMA), it may lag behind adaptive optimizers in convergence speed and localization accuracy without extensive tuning. Additionally, the lack of momentum or advanced learning rate scheduling might have limited SGD’s effectiveness in this scenario. Overall, the performance was moderate, but not better than the default optimizer setup.


"""

from ultralytics import YOLO
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

model = YOLO("yolov8n.pt")

######### freeze 5 layers aptimizer SGD and learning rate 0.005

model.train(
    data="/content/drive/MyDrive/cars_dataset/dataset.yaml",
    epochs=50,
    imgsz=640,
    batch=16,
    name="yolo_freeze5_lr005.v1",
    device=0,
    freeze=5,
    lr0=0.005,
    optimizer="SGD"

)

from IPython.display import Image, display
display(Image(filename="/content/runs/detect/yolo_freeze5_lr005.v12/results.png"))

evaluate_model(
    model_path="/content/runs/detect/yolo_freeze5_lr005.v12/weights/best.pt",
    img_dir="/content/drive/MyDrive/cars_dataset/images/test",
    label_dir="/content/drive/MyDrive/cars_dataset/labels/test"
)

plot_ema_mse(43.00,3.6300
)


predict_show_compare(
    model_path="/content/runs/detect/yolo_freeze5_lr005.v12/weights/best.pt",
    image_dir="/content/drive/MyDrive/cars_dataset/images/test",
    label_dir="/content/drive/MyDrive/cars_dataset/labels/test",
    predict_dir="runs/detect/predict",
    num_images=3
)

"""#**Model 6: YOLOv8n – Freeze First 5 Layers with SGD Optimizer, Learning Rate 0.005, and Batch Size 32**


Parameters:

Model: yolov8n.pt

Freeze: 5 (stem + first 2 backbone blocks)

Optimizer: SGD

Learning rate: 0.005

Epochs: 50

Batch size: 32

Image size: 640x640


This configuration maintains the same freezing strategy (freeze=5) and optimizer (SGD) as the previous experiment but increases the batch size from 16 to 32. The purpose was to investigate whether a larger batch size would stabilize training, improve gradient estimation, or enhance generalization. After 50 epochs, the model achieved a Mean Squared Error (MSE) of 3.4200 and an Exact Match Accuracy (EMA) of 39.50% on the 200-image test set. Interestingly, while the MSE slightly improved compared to the same model trained with a smaller batch size (indicating better bounding box localization), the EMA decreased. This may suggest that larger batches led to more averaged updates, reducing model flexibility in detecting exact counts, especially in images with varied object density. Although training with a larger batch size is generally more stable, it may require additional tuning (e.g., longer training, adjusted learning rate schedules) to fully realize its benefits. In this case, increasing batch size alone did not yield a significant performance improvement.
"""

from ultralytics import YOLO
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

model = YOLO("yolov8n.pt")

######### freeze 5 layers aptimizer SGD and learning rate 0.005 batch size 32

model.train(
    data="/content/drive/MyDrive/cars_dataset/dataset.yaml",
    epochs=50,
    imgsz=640,
    batch=32,
    name="yolo_freeze5_lr005.v2",
    device=0,
    freeze=5,
    lr0=0.005,
    optimizer="SGD"

)

from IPython.display import Image, display
display(Image(filename="/content/runs/detect/yolo_freeze5_lr005.v2/results.png"))

evaluate_model(
    model_path="/content/runs/detect/yolo_freeze5_lr005.v2/weights/best.pt",
    img_dir="/content/drive/MyDrive/cars_dataset/images/test",
    label_dir="/content/drive/MyDrive/cars_dataset/labels/test"
)

plot_ema_mse(39.50, 3.4200
)


predict_show_compare(
    model_path="/content/runs/detect/yolo_freeze5_lr005.v2/weights/best.pt",
    image_dir="/content/drive/MyDrive/cars_dataset/images/test",
    label_dir="/content/drive/MyDrive/cars_dataset/labels/test",
    predict_dir="runs/detect/predict",
    num_images=3
)

"""#Model 7: YOLOv8n – Freeze First 10 Layers with Default Optimizer and Learning Rate (Epochs: 80)

Parameters:

Model: yolov8n.pt

Freeze: 10 (entire backbone + SPPF layer)

Optimizer: default (AdamW)

Learning rate: default (0.01)

Epochs: 80

Batch size: 16

Image size: 640x640


In this configuration, a more aggressive freezing strategy was applied by freezing the first ten layers of the model, which includes the entire backbone and the Spatial Pyramid Pooling - Fast (SPPF) layer. Only the detection head and a portion of the neck were left trainable. To compensate for reduced flexibility, the training duration was extended to 80 epochs. The model achieved a Mean Squared Error (MSE) of 2.5950 and an Exact Match Accuracy (EMA) of 45.00% on a 200-image test set. These results are close to the fully trainable baseline and slightly better than the freeze=5 runs that used fewer epochs. This suggests that increasing the training duration helped the limited trainable layers learn more robust features, partially offsetting the lack of full model adaptation. The experiment highlights that deeper freezing may still yield strong performance when paired with longer training schedules, especially in scenarios with limited computational resources or a desire to retain pretrained backbone weights.
"""

from ultralytics import YOLO

model = YOLO("yolov8n.pt")

###freeze 5 layer deafult optimizer and learning rate(0.01) epoch 80
model.train(
    data="/content/drive/MyDrive/cars_dataset/dataset.yaml",
    epochs=80,
    imgsz=640,
    batch=16,
    name="yolo_freeze580",
    device=0,
    freeze=10
)

display(Image(filename="/content/runs/detect/yolo_freeze580/results.png"))

evaluate_model(
    model_path="/content/runs/detect/yolo_freeze580/weights/best.pt",
    img_dir="/content/drive/MyDrive/cars_dataset/images/test",
    label_dir="/content/drive/MyDrive/cars_dataset/labels/test"
)

plot_ema_mse( 45.00, 2.5950
)


predict_show_compare(
    model_path="/content/runs/detect/yolo_freeze580/weights/best.pt",
    image_dir="/content/drive/MyDrive/cars_dataset/images/test",
    label_dir="/content/drive/MyDrive/cars_dataset/labels/test",
    predict_dir="runs/detect/predict",
    num_images=3
)

"""#Model 8: YOLOv8n – Freeze First 10 Layers with Default Optimizer and Learning Rate (Epochs: 50)

Parameters:

Model: yolov8n.pt

Freeze: 10 (entire backbone + SPPF layer)

Optimizer: default (AdamW)

Learning rate: default (0.01)

Epochs: 50

Batch size: 16

Image size: 640x640

This experiment froze the first ten layers of the YOLOv8n model, which includes the full backbone and the SPPF (Spatial Pyramid Pooling - Fast) layer, leaving only the detection head and parts of the neck trainable. The model was trained for 50 epochs using the default optimizer and learning rate. It achieved a Mean Squared Error (MSE) of 3.4250 and an Exact Match Accuracy (EMA) of 47.50% on the 200-image test set. While the EMA is the highest among all experiments, the MSE is noticeably higher than configurations with fewer frozen layers. This result suggests that although the model is relatively good at predicting the correct number of objects in some images (reflected in EMA), its overall bounding box localization accuracy is less precise. The trade-off between freezing for efficiency and allowing enough trainable parameters for fine-tuning is clearly illustrated here. It also confirms that while freezing the entire backbone can still yield reasonable results, it may require either more training epochs (as seen in the freeze=10 at 80 epochs) or additional fine-tuning strategies to reduce localization errors.
"""

from ultralytics import YOLO

model = YOLO("yolov8n.pt")

###freeze 10 layer deafult optimizer and learning rate(0.01)
model.train(
    data="/content/drive/MyDrive/cars_dataset/dataset.yaml",
    epochs=50,
    imgsz=640,
    batch=16,
    name="yolo_freeze10",
    device=0,
    freeze=10
)

display(Image(filename="/content/runs/detect/yolo_freeze10/results.png"))

evaluate_model(
    model_path="/content/runs/detect/yolo_freeze10/weights/best.pt",
    img_dir="/content/drive/MyDrive/cars_dataset/images/test",
    label_dir="/content/drive/MyDrive/cars_dataset/labels/test"
)

plot_ema_mse(47.50, 3.4250
)


predict_show_compare(
    model_path="/content/runs/detect/yolo_freeze10/weights/best.pt",
    image_dir="/content/drive/MyDrive/cars_dataset/images/test",
    label_dir="/content/drive/MyDrive/cars_dataset/labels/test",
    predict_dir="runs/detect/predict4",
    num_images=3
)

"""#Model 9: YOLOv8n – Freeze First 21 Layers (All Except Detection Head), Default Optimizer and Learning Rate

Parameters:

Model: yolov8n.pt

Freeze: 21 (entire model except detection head)

Optimizer: default (AdamW)

Learning rate: default (0.01)

Epochs: 50

Batch size: 16

Image size: 640x640

:
In this experiment, all layers of the YOLOv8n model except for the detection head were frozen using freeze=21, leaving only the final prediction layers trainable. The goal was to evaluate how well the detection head alone could adapt to the car counting task without modifying any of the pretrained feature extractors. After 50 epochs, the model performed poorly, with a Mean Squared Error (MSE) of 14.6300 and an Exact Match Accuracy (EMA) of 20.00% on the 200-image test set. These results indicate a significant drop in both localization and counting accuracy. The lack of trainable capacity in the backbone and neck prevented the model from adjusting to the specific characteristics of the dataset, especially for varied object appearances and densities. This experiment confirms that freezing the entire feature extraction pipeline leaves the model too rigid to adapt effectively and that at least part of the backbone and neck must remain trainable to achieve acceptable performance in domain-specific tasks such as car counting.


"""

from ultralytics import YOLO

model = YOLO("yolov8n.pt")

###freeze 21 layer deafult optimizer and learning rate(0.01)
model.train(
    data="/content/drive/MyDrive/cars_dataset/dataset.yaml",
    epochs=50,
    imgsz=640,
    batch=16,
    name="yolo_freeze21",
    device=0,
    freeze=21
)

display(Image(filename="/content/runs/detect/yolo_freeze21/results.png"))

evaluate_model(
    model_path="/content/runs/detect/yolo_freeze21/weights/best.pt",
    img_dir="/content/drive/MyDrive/cars_dataset/images/test",
    label_dir="/content/drive/MyDrive/cars_dataset/labels/test"
)

plot_ema_mse( 20.00, 14.6300
)


predict_show_compare(
    model_path="/content/runs/detect/yolo_freeze21/weights/best.pt",
    image_dir="/content/drive/MyDrive/cars_dataset/images/test",
    label_dir="/content/drive/MyDrive/cars_dataset/labels/test",
    predict_dir="runs/detect/predict4",
    num_images=3
)

"""# Comparative Analysis

A comprehensive comparison of all trained YOLOv8n models reveals how different configurations—such as freezing strategies, learning rates, optimizers, batch sizes, and epoch durations—affect performance on the car counting task. The baseline model, yolo_car_counting_v8n, trained with all layers unfrozen and default hyperparameters, achieved an Exact Match Accuracy (EMA) of 46.50% and a Mean Squared Error (MSE) of 2.7350, serving as a strong starting point.

Freezing the first five layers in yolo_freeze5 yielded similar performance (EMA: 44.50%, MSE: 2.2700), suggesting that freezing low-level feature extractors does not severely impact model accuracy and may even slightly improve localization consistency. In yolo_freeze5_lr001, the optimizer was set to Adam with a lower learning rate (0.001), resulting in decreased performance (EMA: 42.50%, MSE: 3.4800), possibly due to slower convergence or underfitting. With a slightly higher learning rate in yolo_freeze5_lr005, performance remained similar (EMA: 42.00%, MSE: 3.2700), indicating that adjusting learning rate alone, without other changes, did not significantly benefit training.

Switching to the SGD optimizer in yolo_freeze5_lr005.v1 yielded a modest increase in EMA to 43.00%, but also the highest MSE among freeze=5 models (3.6300), suggesting slightly better count prediction but poorer bounding box localization. In yolo_freeze5_lr005.v2, the batch size was doubled to 32 while keeping the optimizer and learning rate the same. This reduced the MSE slightly (3.4200), but EMA dropped to 39.50%, likely due to over-smoothing of gradients with larger batch updates.

More aggressive freezing was applied in yolo_freeze10, which freezes the entire backbone and SPPF layer. Surprisingly, it achieved the highest EMA of all models (47.50%), although its MSE was higher at 3.4250, suggesting improved count predictions but less accurate bounding boxes. Extending training to 80 epochs in yolo_freeze580 significantly improved the model's localization performance (MSE: 2.5950) with only a slight decrease in EMA (45.00%), showing that longer training can partially compensate for reduced trainable layers.

Finally, yolo_freeze21, where only the detection head was left trainable, suffered the worst performance (EMA: 20.00%, MSE: 14.6300), clearly demonstrating that the backbone and neck must be at least partially unfrozen for the model to adapt effectively to a new dataset.

In summary, the results confirm that partial freezing (like in yolo_freeze5) provides a good trade-off between performance and training efficiency. However, excessive freezing—as in yolo_freeze21—severely limits the model's ability to generalize. Moreover, modifying learning rates and optimizers requires careful tuning, as arbitrary changes may reduce accuracy unless supported by longer training or more adaptive strategies.
"""

import matplotlib.pyplot as plt
import numpy as np

models = [
    "Baseline",
    "Freeze5\nDefault",
    "Freeze5\nAdam-0.001",
    "Freeze5\nAdam-0.005",
    "Freeze5\nSGD-0.005",
    "Freeze5\nSGD-BS32",
    "Freeze10\n50ep",
    "Freeze10\n80ep",
    "Freeze21\nOnly Head"
]

ema_scores = [46.5, 44.5, 42.5, 42.0, 43.0, 39.5, 47.5, 45.0, 20.0]
mse_scores = [2.735, 2.270, 3.480, 3.270, 3.630, 3.420, 3.425, 2.595, 14.630]

x = np.arange(len(models))
width = 0.35

fig, ax1 = plt.subplots(figsize=(12, 6))

bar1 = ax1.bar(x - width/2, ema_scores, width, label='EMA (%)', color='skyblue')
ax1.set_ylabel('Exact Match Accuracy (%)', color='skyblue')
ax1.set_ylim(0, 100)

ax2 = ax1.twinx()
bar2 = ax2.bar(x + width/2, mse_scores, width, label='MSE', color='salmon')
ax2.set_ylabel('Mean Squared Error (MSE)', color='salmon')
ax2.set_ylim(0, max(mse_scores) + 1)

plt.title("YOLOv8n Model Comparison: EMA vs MSE")
ax1.set_xticks(x)
ax1.set_xticklabels(models, rotation=30, ha="right")
fig.legend(loc="upper right", bbox_to_anchor=(0.9, 0.9))
plt.grid(axis='y', linestyle='--', alpha=0.5)

plt.tight_layout()
plt.show()